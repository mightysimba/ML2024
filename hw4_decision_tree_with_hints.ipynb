{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_df = pd.read_csv('C:\\\\Users\\\\FILMINVASION\\\\Downloads\\\\ML2024\\\\train.csv')\n",
    "test_df = pd.read_csv('C:\\\\Users\\\\FILMINVASION\\\\Downloads\\\\ML2024\\\\test.csv')\n",
    "\n",
    "# load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "info:  None\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FILMINVASION\\AppData\\Local\\Temp\\ipykernel_7732\\363686179.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
      "C:\\Users\\FILMINVASION\\AppData\\Local\\Temp\\ipykernel_7732\\363686179.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
      "C:\\Users\\FILMINVASION\\AppData\\Local\\Temp\\ipykernel_7732\\363686179.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
      "C:\\Users\\FILMINVASION\\AppData\\Local\\Temp\\ipykernel_7732\\363686179.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)\n",
      "C:\\Users\\FILMINVASION\\AppData\\Local\\Temp\\ipykernel_7732\\363686179.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "\n",
    "# make a research on the data and determine the best way to handle missing values\n",
    "print(\"\\ninfo: \", train_df.info())\n",
    "\n",
    "#Дивлюсь які дані відсутні\n",
    "missing_data = train_df.isnull().sum()\n",
    "print(missing_data)\n",
    "\n",
    "# implement the best way to handle missing values\n",
    "train_df.drop(columns=['Cabin', 'Name', 'Ticket'], inplace=True)\n",
    "test_df.drop(columns=['Cabin', 'Name', 'Ticket'], inplace=True)\n",
    "\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
    "\n",
    "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
    "# implement the best way to handle categorical values (encoding)\n",
    "\n",
    "train_df['Embarked'] = train_df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "test_df['Embarked'] = test_df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\n",
    "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validation method\n",
    "n_splits = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in skf.split(train_df, train_df['Survived']):\n",
    "    X_train_fold, X_val_fold = train_df.iloc[train_index], train_df.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = train_df['Survived'].iloc[train_index], train_df['Survived'].iloc[val_index]\n",
    "\n",
    "    \n",
    "# use StratifiedKFold to split the data into folds or KFold if you don't need stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Training Score (accuracy): 0.7957567007720796\n",
      "Best Model Accuracy on Training Data: 0.8013468013468014\n",
      "Estimated Generalization Error: 0.22669323959575668\n"
     ]
    }
   ],
   "source": [
    "# define the regression model\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# define the grid search with cross validation using previously defined validation method\n",
    "\n",
    "regression_grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "X_train = train_df.drop(columns=['Survived']) \n",
    "y_train = train_df['Survived']                 \n",
    "\n",
    "# train the model\n",
    "regression_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", regression_grid_search.best_params_)\n",
    "print(\"Best Training Score (accuracy):\", regression_grid_search.best_score_)\n",
    "\n",
    "best_model = regression_grid_search.best_estimator_\n",
    "regression_train_accuracy = accuracy_score(y_train, best_model.predict(X_train))\n",
    "\n",
    "\n",
    "\n",
    "# print the best score on train and validation data, estimate the generalization error\n",
    "print(\"Best Model Accuracy on Training Data:\", regression_train_accuracy)\n",
    "cv_results = regression_grid_search.cv_results_['mean_test_score']\n",
    "regression_generalization_error = np.mean(1 - cv_results)\n",
    "print(\"Estimated Generalization Error:\", regression_generalization_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Best Training Score (accuracy): 0.8271483271608812\n",
      "Best Model Accuracy on Training Data: 0.8271604938271605\n",
      "Estimated Generalization Error: 0.22791082841048318\n"
     ]
    }
   ],
   "source": [
    "# define the decision tree model\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# define the grid search with cross validation using previously defined validation method\n",
    "decision_tree_grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# train the model\n",
    "X_train = train_df.drop(columns=['Survived'])\n",
    "y_train = train_df['Survived']  \n",
    "decision_tree_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", decision_tree_grid_search.best_params_)\n",
    "print(\"Best Training Score (accuracy):\", decision_tree_grid_search.best_score_)\n",
    "\n",
    "# print the best score on train and validation data, estimate the generalization error\n",
    "best_model = decision_tree_grid_search.best_estimator_\n",
    "decision_tree_train_accuracy = accuracy_score(y_train, best_model.predict(X_train))\n",
    "\n",
    "print(\"Best Model Accuracy on Training Data:\", decision_tree_train_accuracy)\n",
    "\n",
    "cv_results = decision_tree_grid_search.cv_results_['mean_test_score']\n",
    "decision_tree_generalization_error = np.mean(1 - cv_results)\n",
    "\n",
    "print(\"Estimated Generalization Error:\", decision_tree_generalization_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Best Hyperparameters (Logistic Regression): {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Training Accuracy (Logistic Regression): 0.8013468013468014\n",
      "Cross-Validation Accuracy (Logistic Regression): 0.7957567007720796\n",
      "Generalization Error (Logistic Regression): 0.22669323959575668\n",
      "\n",
      "Decision Tree Results:\n",
      "Best Hyperparameters (Decision Tree): {'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Training Accuracy (Decision Tree): 0.8271604938271605\n",
      "Cross-Validation Accuracy (Decision Tree): 0.8271483271608812\n",
      "Generalization Error (Decision Tree): 0.22791082841048318\n",
      "\n",
      "Cross-Validation Accuracy (Logistic Regression): 0.7957567007720796 vs Cross-Validation Accuracy (Decision Tree): 0.8271483271608812\n"
     ]
    }
   ],
   "source": [
    "# compare the results of the two models\n",
    "# make a conclusion on which model is better and why\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(\"Best Hyperparameters (Logistic Regression):\", regression_grid_search.best_params_)\n",
    "print(\"Training Accuracy (Logistic Regression):\", regression_train_accuracy)\n",
    "print(\"Cross-Validation Accuracy (Logistic Regression):\", regression_grid_search.best_score_)\n",
    "print(\"Generalization Error (Logistic Regression):\", regression_generalization_error)\n",
    "\n",
    "# Decision Tree Results\n",
    "print(\"\\nDecision Tree Results:\")\n",
    "print(\"Best Hyperparameters (Decision Tree):\", decision_tree_grid_search.best_params_)\n",
    "print(\"Training Accuracy (Decision Tree):\", decision_tree_train_accuracy)\n",
    "print(\"Cross-Validation Accuracy (Decision Tree):\", decision_tree_grid_search.best_score_)\n",
    "print(\"Generalization Error (Decision Tree):\", decision_tree_generalization_error)\n",
    "\n",
    "print(\"\\nCross-Validation Accuracy (Logistic Regression):\", regression_grid_search.best_score_, 'vs ' \"Cross-Validation Accuracy (Decision Tree):\", decision_tree_grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.8013468013468014\n",
      "Decision Tree Training Accuracy: 0.8271604938271605\n"
     ]
    }
   ],
   "source": [
    "# retrain the best models (both regression and DT) on the whole train data\n",
    "logreg_best_model = regression_grid_search.best_estimator_\n",
    "logreg_best_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_train_accuracy = accuracy_score(y_train, logreg_best_model.predict(X_train))\n",
    "print(\"Logistic Regression Training Accuracy:\", logreg_train_accuracy)\n",
    "\n",
    "#DT\n",
    "decision_tree_best_model = decision_tree_grid_search.best_estimator_\n",
    "decision_tree_best_model.fit(X_train, y_train)\n",
    "\n",
    "decision_tree_train_accuracy = accuracy_score(y_train, decision_tree_best_model.predict(X_train))\n",
    "print(\"Decision Tree Training Accuracy:\", decision_tree_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded to Kaggle\n",
      "logreg_submission.csv: Score: 0.76555\n",
      "decision_tree_submission.csv Score: 0.77990\n",
      "\n",
      "Cross validation data\n",
      "Cross-Validation Accuracy (Logistic Regression): 0.7957567007720796\n",
      "Cross-Validation Accuracy (Decision Tree): 0.8271483271608812\n",
      "Виходячи із результату моїх моделей на Кагглі схоже що моделі перенавчені. Думаю тут можна було б застосувати регуляризацію чи якийсь інший метод.\n",
      "На логістичній регресії може треба було погратись з фічами та/або гіперпараметрамию. \n",
      "Відповідно до десіжен трі то можна було б застосувати бустінг або рендом форест\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "# do the same preprocessing as for train data\n",
    "\n",
    "# using retrained models make predictions on the test data for both regression and DT models\n",
    "logreg_predictions = logreg_best_model.predict(test_df)\n",
    "\n",
    "decision_tree_predictions = decision_tree_best_model.predict(test_df)\n",
    "\n",
    "logreg_submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': logreg_predictions\n",
    "})\n",
    "\n",
    "decision_tree_submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': decision_tree_predictions\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# save the predictions to a file\n",
    "logreg_submission.to_csv('logreg_submission.csv', index=False)\n",
    "decision_tree_submission.to_csv('decision_tree_submission.csv', index=False)\n",
    "# upload the predictions to Kaggle and make a submission\n",
    "# report the score you got and compare it with the score you got on the validation data\n",
    "print(\"Data uploaded to Kaggle\")\n",
    "print('logreg_submission.csv: Score: 0.76555')\n",
    "print('decision_tree_submission.csv Score: 0.77990')\n",
    "\n",
    "print(\"\\nCross validation data\")\n",
    "print(\"Cross-Validation Accuracy (Logistic Regression):\", regression_grid_search.best_score_)\n",
    "print(\"Cross-Validation Accuracy (Decision Tree):\", decision_tree_grid_search.best_score_)\n",
    "\n",
    "# make a conclusion on how well the models generalizes\n",
    "\n",
    "print(\"Виходячи із результату моїх моделей на Кагглі схоже що моделі перенавчені. Думаю тут можна було б застосувати регуляризацію чи якийсь інший метод.\\nНа логістичній регресії може треба було погратись з фічами та/або гіперпараметрамию. \\nВідповідно до десіжен трі то можна було б застосувати бустінг або рендом форест\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
